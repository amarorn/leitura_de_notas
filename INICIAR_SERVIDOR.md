# ğŸš€ Como Iniciar o Servidor

## OpÃ§Ã£o 1: Usando npm (Recomendado)

```bash
# Na raiz do projeto
npm run server
```

## OpÃ§Ã£o 2: Manualmente

```bash
cd server_python
source venv/bin/activate
python main.py
```

## OpÃ§Ã£o 3: Usando o script

```bash
cd server_python
./run.sh
```

## âœ… Verificar se estÃ¡ funcionando

Abra outro terminal e teste:

```bash
curl http://localhost:5001/api/health
```

Deve retornar:
```json
{
  "status": "OK",
  "message": "Servidor rodando",
  "llm_provider": "ollama",
  "ocr_engine": "paddleocr"
}
```

## ğŸ”§ Se usar Ollama

Certifique-se de que o Ollama estÃ¡ rodando:

```bash
# Verificar se estÃ¡ rodando
ollama list

# Se nÃ£o estiver, iniciar:
ollama serve
```

Em outro terminal, baixe o modelo (se ainda nÃ£o tiver):

```bash
ollama pull llama3.2
```

## ğŸ”§ Se usar OpenAI

Configure no arquivo `server_python/.env`:

```env
PORT=5001
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-sua-chave-aqui
OCR_ENGINE=paddleocr
```

## ğŸ› Problemas Comuns

### Porta 5001 em uso
```bash
lsof -ti:5001 | xargs kill
```

### Ollama nÃ£o encontrado
```bash
brew install ollama
ollama pull llama3.2
```

### Erro de dependÃªncias
```bash
cd server_python
source venv/bin/activate
pip install -r requirements.txt
```

