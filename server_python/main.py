"""
Servidor FastAPI com LlamaIndex + OCR para processamento de boletins escolares
"""
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings, Document
from llama_index.readers.file import ImageReader
from llama_index.llms.openai import OpenAI
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
import os
import shutil
import tempfile
from pathlib import Path
from typing import Optional
import json
from dotenv import load_dotenv

# OCR imports
try:
    from paddleocr import PaddleOCR
    PADDLEOCR_AVAILABLE = True
except ImportError:
    PADDLEOCR_AVAILABLE = False

try:
    import pytesseract
    from PIL import Image
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False

load_dotenv()

app = FastAPI(title="Sistema de An√°lise de Boletim Escolar")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configura√ß√µes
UPLOAD_DIR = Path(__file__).parent / "uploads"
UPLOAD_DIR.mkdir(exist_ok=True)

# Configurar LLM (OpenAI ou Ollama local)
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openai")  # "openai" ou "ollama"

if LLM_PROVIDER == "openai":
    api_key = os.getenv("OPENAI_API_KEY")
    # Verificar se a chave √© v√°lida (n√£o √© a chave de exemplo)
    if not api_key or api_key.strip() == "" or "sua-chave" in api_key.lower() or "your-api-key" in api_key.lower():
        print("‚ö†Ô∏è  OPENAI_API_KEY n√£o configurada ou √© uma chave de exemplo.")
        print("üîÑ Usando Ollama como fallback (gratuito e local).")
        print("üí° Para usar OpenAI, configure uma chave v√°lida em server_python/.env")
        LLM_PROVIDER = "ollama"
    else:
        Settings.llm = OpenAI(api_key=api_key, model="gpt-4o-mini", temperature=0)
        # Usar modelo de embeddings mais recente e dispon√≠vel
        try:
            Settings.embed_model = OpenAIEmbedding(
                api_key=api_key,
                model="text-embedding-3-small"  # Modelo mais recente e dispon√≠vel
            )
            print("‚úÖ Usando OpenAI GPT-4o-mini com embeddings text-embedding-3-small")
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao configurar embeddings: {e}")
            print("üîÑ Tentando com modelo alternativo...")
            try:
                Settings.embed_model = OpenAIEmbedding(
                    api_key=api_key,
                    model="text-embedding-ada-002"
                )
                print("‚úÖ Usando OpenAI GPT-4o-mini com embeddings text-embedding-ada-002")
            except Exception as e2:
                print(f"‚ùå Erro ao configurar embeddings alternativo: {e2}")
                print("üí° Usando embeddings locais (HuggingFace) como fallback...")
                try:
                    # Usar embeddings locais do HuggingFace
                    Settings.embed_model = HuggingFaceEmbedding(model_name="sentence-transformers/all-MiniLM-L6-v2")
                    print("‚úÖ Usando embeddings locais (HuggingFace)")
                except Exception as e3:
                    print(f"‚ö†Ô∏è  Erro ao configurar embeddings locais: {e3}")
                    print("üí° Continuando sem embeddings customizados (usando padr√£o do LlamaIndex)")
                    # N√£o configurar embed_model, deixar LlamaIndex usar o padr√£o
if LLM_PROVIDER == "ollama":
    try:
        Settings.llm = Ollama(model="llama3.2", request_timeout=120.0)
        # Ollama n√£o precisa de embeddings separados, usa os do modelo
        print("‚úÖ Usando Ollama (llama3.2)")
        print("üí° Certifique-se de que o Ollama est√° rodando: ollama serve")
    except Exception as e:
        print(f"‚ùå Erro ao configurar Ollama: {e}")
        print("üí° Instale o Ollama: brew install ollama")
        print("üí° Ou configure uma chave OpenAI v√°lida no arquivo .env")
        raise

# OCR Engine (paddleocr ou tesseract)
OCR_ENGINE = os.getenv("OCR_ENGINE", "paddleocr")  # "paddleocr" ou "tesseract"
print(f"‚úÖ OCR Engine: {OCR_ENGINE}")


def calculate_averages(disciplina: dict, media_minima: float = 7.0) -> dict:
    """Calcula m√©dias e status da disciplina"""
    notas = [n for n in disciplina.get("notas", []) if n is not None]
    qtd_notas = len(notas)
    
    # M√©dia provis√≥ria
    media_provisoria = disciplina.get("media_provisoria")
    if media_provisoria is None and qtd_notas > 0:
        media_provisoria = sum(notas) / qtd_notas
    
    # Pontos extras
    pontos_extras = disciplina.get("pontos_extras", 0) or 0
    
    # M√©dia parcial (com pontos extras, limitada a 10)
    media_parcial = disciplina.get("media_parcial")
    if media_parcial is None:
        media_parcial = min((media_provisoria or 0) + pontos_extras, 10)
    
    # Status e nota necess√°ria
    todas_notas_lancadas = qtd_notas >= 3 and all(n is not None for n in disciplina.get("notas", [])[:3])
    
    nota_necessaria = None
    if not todas_notas_lancadas and qtd_notas > 0:
        faltam_notas = 3 - qtd_notas
        soma_atual = sum(notas) + pontos_extras
        total_necessario = media_minima * 3
        nota_faltante = (total_necessario - soma_atual) / faltam_notas if faltam_notas > 0 else 0
        
        if 0 < nota_faltante <= 10:
            nota_necessaria = round(nota_faltante, 2)
    
    # Status
    if qtd_notas == 0:
        status = "Sem Notas"
        nota_necessaria = media_minima
    elif media_parcial >= media_minima:
        status = "Aprovado"
    elif media_parcial >= media_minima * 0.6:
        status = "Em Recupera√ß√£o"
    else:
        status = "Reprovado"
    
    return {
        "media_provisoria": round(media_provisoria or 0, 2),
        "media_parcial": round(media_parcial, 2),
        "qtd_notas": qtd_notas,
        "nota_necessaria": nota_necessaria,
        "status": status,
        "media_minima": media_minima
    }


def extract_text_with_ocr(image_path: str) -> str:
    """
    Extrai texto da imagem usando OCR (PaddleOCR ou Tesseract)
    """
    print(f"üîç Iniciando OCR com {OCR_ENGINE}...")
    
    if OCR_ENGINE == "paddleocr":
        if not PADDLEOCR_AVAILABLE:
            raise HTTPException(status_code=500, detail="PaddleOCR n√£o est√° instalado. Execute: pip install paddleocr")
        
        try:
            # Tentar inicializar PaddleOCR com portugu√™s
            # Se falhar, tentar ingl√™s como fallback
            ocr = None
            try:
                ocr = PaddleOCR(use_angle_cls=True, lang='por')
                print("‚úÖ PaddleOCR inicializado com portugu√™s")
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao inicializar PaddleOCR com 'por': {e}")
                try:
                    print("üîÑ Tentando com 'en' (ingl√™s) como fallback...")
                    ocr = PaddleOCR(use_angle_cls=True, lang='en')
                    print("‚úÖ PaddleOCR inicializado com ingl√™s")
                except Exception as e2:
                    print(f"‚ùå Erro ao inicializar PaddleOCR com 'en': {e2}")
                    # Se Tesseract estiver dispon√≠vel, usar como fallback
                    if TESSERACT_AVAILABLE:
                        print("üîÑ Fallback autom√°tico para Tesseract...")
                        return extract_text_with_tesseract(image_path)
                    else:
                        raise HTTPException(
                            status_code=500, 
                            detail=f"PaddleOCR falhou e Tesseract n√£o est√° dispon√≠vel. Erro: {str(e2)}"
                        )
            
            if ocr is None:
                raise HTTPException(status_code=500, detail="N√£o foi poss√≠vel inicializar PaddleOCR")
            
            result = ocr.ocr(image_path, cls=True)
            
            # Extrair texto de todos os resultados
            text_lines = []
            if result and result[0]:
                for line in result[0]:
                    if line and len(line) >= 2:
                        text_lines.append(line[1][0])  # line[1][0] √© o texto reconhecido
            
            text = "\n".join(text_lines)
            print(f"‚úÖ OCR conclu√≠do. Texto extra√≠do: {len(text)} caracteres")
            return text
        except HTTPException:
            raise
        except Exception as e:
            print(f"‚ùå Erro no PaddleOCR: {str(e)}")
            # Se Tesseract estiver dispon√≠vel, usar como fallback
            if TESSERACT_AVAILABLE:
                print("üîÑ Fallback autom√°tico para Tesseract devido a erro no PaddleOCR...")
                try:
                    return extract_text_with_tesseract(image_path)
                except Exception as e2:
                    raise HTTPException(status_code=500, detail=f"Erro no OCR (PaddleOCR e Tesseract falharam): {str(e2)}")
            else:
                raise HTTPException(status_code=500, detail=f"Erro no OCR: {str(e)}")
    
    elif OCR_ENGINE == "tesseract":
        return extract_text_with_tesseract(image_path)
    else:
        raise HTTPException(status_code=500, detail=f"OCR engine '{OCR_ENGINE}' n√£o suportado. Use 'paddleocr' ou 'tesseract'")


def extract_text_with_tesseract(image_path: str) -> str:
    """
    Extrai texto usando Tesseract OCR
    """
    if not TESSERACT_AVAILABLE:
        raise HTTPException(status_code=500, detail="Tesseract n√£o est√° instalado. Execute: pip install pytesseract pillow")
    
    try:
        image = Image.open(image_path)
        # Tentar portugu√™s primeiro, se falhar usar ingl√™s
        try:
            text = pytesseract.image_to_string(image, lang='por')
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao usar Tesseract com 'por': {e}")
            print("üîÑ Tentando com 'eng' (ingl√™s)...")
            text = pytesseract.image_to_string(image, lang='eng')
        
        print(f"‚úÖ OCR conclu√≠do. Texto extra√≠do: {len(text)} caracteres")
        return text
    except Exception as e:
        print(f"‚ùå Erro no Tesseract: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro no OCR: {str(e)}")


def extract_boletim_data_with_llamaindex(image_path: str) -> dict:
    """
    Extrai dados do boletim usando LlamaIndex + OCR
    """
    print(f"üìÑ Processando imagem: {image_path}")
    
    # Prompt otimizado para extra√ß√£o estruturada
    extraction_prompt = """
Voc√™ √© um especialista em an√°lise de boletins escolares. Extraia TODOS os dados do boletim e retorne APENAS um JSON v√°lido, sem texto adicional.

Estrutura esperada do JSON:
{
  "aluno": "NOME COMPLETO DO ALUNO",
  "matricula": "N√öMERO DA MATR√çCULA",
  "turma": "C√ìDIGO DA TURMA (ex: 7A, 7B)",
  "ano": 2024,
  "bimestre": "1¬∫ Bimestre" ou "2¬∫ Bimestre" etc,
  "disciplinas": [
    {
      "nome": "NOME DA DISCIPLINA (exatamente como aparece)",
      "faltas": 0,
      "notas": [10.0, 9.5, null],  // Array com 3 notas (1¬™ AV, 2¬™ AV, 3¬™ AV), use null se n√£o houver
      "pontos_extras": 0,
      "media_provisoria": 9.75,  // Se dispon√≠vel no boletim
      "media_parcial": 10.0      // Se dispon√≠vel no boletim
    }
  ]
}

REGRAS IMPORTANTES:
1. Extraia TODAS as disciplinas encontradas no boletim (pode variar de 13 a 25+ dependendo da s√©rie)
2. As notas devem ser n√∫meros decimais ou null se n√£o houver nota
3. Mantenha os nomes das disciplinas EXATAMENTE como aparecem (com acentos e mai√∫sculas)
4. Se houver subtabelas (ex: Biologia I / Biologia II, F√≠sica I / F√≠sica II, Literatura / An√°lise Lingu√≠stica / Produ√ß√£o de Texto), trate cada uma como uma disciplina separada com seu nome completo
5. Valores vazios ou tra√ßos (-) devem ser null
6. Retorne APENAS o JSON, sem markdown, sem explica√ß√µes, sem ```json
7. Para faltas, use 0 se n√£o houver faltas ou o n√∫mero exato de faltas

Disciplinas comuns (podem variar por s√©rie):
- EMPREENDEDORISMO
- FILOSOFIA
- GEOGRAFIA
- HIST√ìRIA
- SOCIOLOGIA
- BIOLOGIA (pode ter subtabelas: Biologia I, Biologia II)
- F√çSICA (pode ter subtabelas: F√≠sica I, F√≠sica II)
- QU√çMICA
- REDA√á√ÉO
- √âTICA E CIDADANIA
- CI√äNCIAS
- EDUCA√á√ÉO F√çSICA
- ENSINO DA ARTE
- ESPANHOL
- INGL√äS
- L√çNGUA PORTUGUESA (pode ter subtabelas: Literatura, An√°lise Lingu√≠stica, Produ√ß√£o de Texto)
- MATEM√ÅTICA
- PROJETO DE VIDA
- UNIDADE CURRICULAR DE HUMANAS
- UNIDADE CURRICULAR DE NATUREZA
- TRAJET√ìRIA DE LEITURA E ESCRITA

IMPORTANTE: 
- Se uma disciplina tiver subtabelas (ex: Biologia I / Biologia II), trate cada uma como uma disciplina separada
- Mantenha o nome completo da disciplina/subdisciplina exatamente como aparece
- Extraia TODAS as disciplinas encontradas, n√£o apenas as listadas acima

Extraia todos os dados vis√≠veis no boletim e retorne o JSON completo.
"""
    
    try:
        # Extrair texto usando OCR
        ocr_text = extract_text_with_ocr(image_path)
        
        # Criar documento do LlamaIndex com o texto extra√≠do
        doc = Document(text=ocr_text)
        docs = [doc]
        
        print(f"üìù Texto OCR preparado para processamento com LLM")
        
        # Criar √≠ndice vetorial
        index = VectorStoreIndex.from_documents(docs)
        query_engine = index.as_query_engine()
        
        # Extrair dados estruturados
        print("ü§ñ Processando com LLM para extra√ß√£o estruturada...")
        try:
            response = query_engine.query(extraction_prompt)
        except Exception as e:
            error_msg = str(e)
            if "invalid_api_key" in error_msg.lower() or "incorrect api key" in error_msg.lower() or "401" in error_msg:
                raise HTTPException(
                    status_code=401,
                    detail="Chave da API OpenAI inv√°lida. Configure uma chave v√°lida em server_python/.env ou use Ollama (gratuito). Veja CONFIGURACAO_LLM.md para mais detalhes."
                )
            elif "model_not_found" in error_msg.lower() or "does not have access" in error_msg.lower() or "403" in error_msg or "text-embedding" in error_msg.lower():
                raise HTTPException(
                    status_code=403,
                    detail="Modelo de embeddings n√£o dispon√≠vel no seu projeto OpenAI. Reinicie o servidor para usar embeddings locais como fallback."
                )
            raise
        
        # Parsear resposta JSON
        response_text = str(response).strip()
        
        # Remover markdown code blocks se houver
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()
        
        # Parsear JSON
        try:
            data = json.loads(response_text)
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è  Erro ao parsear JSON: {e}")
            print(f"Resposta recebida: {response_text[:500]}")
            # Tentar extrair JSON do texto
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
            else:
                raise HTTPException(status_code=500, detail="N√£o foi poss√≠vel extrair JSON v√°lido da resposta do LLM")
        
        print(f"‚úÖ Dados extra√≠dos: {len(data.get('disciplinas', []))} disciplinas")
        return data
        
    except Exception as e:
        print(f"‚ùå Erro na extra√ß√£o: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro ao processar imagem: {str(e)}")


@app.get("/api/health")
async def health_check():
    """Health check"""
    return {
        "status": "OK",
        "message": "Servidor rodando",
        "llm_provider": LLM_PROVIDER,
        "ocr_engine": OCR_ENGINE
    }


@app.post("/api/upload")
async def upload_boletim(boletim: UploadFile = File(..., alias="boletim")):
    """
    Upload e processamento de boletim escolar
    """
    # Validar tipo de arquivo
    if not boletim.content_type or not boletim.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="Apenas imagens s√£o permitidas")
    
    # Salvar arquivo tempor√°rio
    temp_file = UPLOAD_DIR / f"{os.urandom(8).hex()}-{boletim.filename}"
    
    try:
        with open(temp_file, "wb") as buffer:
            shutil.copyfileobj(boletim.file, buffer)
        
        print(f"üì§ Arquivo recebido: {boletim.filename} ({temp_file.stat().st_size} bytes)")
        
        # Extrair dados com LlamaIndex
        extracted_data = extract_boletim_data_with_llamaindex(str(temp_file))
        
        # Processar disciplinas (calcular m√©dias)
        disciplinas_processadas = []
        for disciplina in extracted_data.get("disciplinas", []):
            calculos = calculate_averages(disciplina, 7.0)
            disciplina_completa = {
                **disciplina,
                **calculos
            }
            disciplinas_processadas.append(disciplina_completa)
        
        # Atualizar dados extra√≠dos
        extracted_data["disciplinas"] = disciplinas_processadas
        
        # Limpar arquivo tempor√°rio
        temp_file.unlink()
        
        return JSONResponse({
            "success": True,
            "dados": extracted_data
        })
        
    except HTTPException:
        raise
    except Exception as e:
        # Limpar arquivo em caso de erro
        if temp_file.exists():
            temp_file.unlink()
        print(f"‚ùå Erro no upload: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro ao processar imagem: {str(e)}")


@app.post("/api/calculate")
async def calculate_medias(data: dict):
    """
    Recalcula m√©dias com m√©dia m√≠nima customizada
    """
    disciplinas = data.get("disciplinas", [])
    media_minima = data.get("mediaMinima", 7.0)
    
    if not disciplinas:
        raise HTTPException(status_code=400, detail="Dados inv√°lidos")
    
    disciplinas_processadas = []
    for disciplina in disciplinas:
        calculos = calculate_averages(disciplina, media_minima)
        disciplina_completa = {
            **disciplina,
            **calculos
        }
        disciplinas_processadas.append(disciplina_completa)
    
    return JSONResponse({
        "success": True,
        "disciplinas": disciplinas_processadas
    })


if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 5001))
    print(f"\nüöÄ Iniciando servidor na porta {port}...")
    print(f"üì° API dispon√≠vel em http://localhost:{port}\n")
    uvicorn.run(app, host="0.0.0.0", port=port)

