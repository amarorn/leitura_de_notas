# ğŸš€ MigraÃ§Ã£o para LlamaIndex + OCR

Este projeto foi migrado para usar **LlamaIndex + OCR** em vez de Tesseract.js puro. Isso oferece extraÃ§Ã£o de dados muito mais precisa e estruturada.

## ğŸ“Š ComparaÃ§Ã£o

| Aspecto | Antes (Tesseract.js) | Agora (LlamaIndex) |
|---------|---------------------|-------------------|
| **PrecisÃ£o** | ~70-80% (muitos erros de parsing) | ~95%+ (LLM entende contexto) |
| **EstruturaÃ§Ã£o** | Regex complexo, frÃ¡gil | JSON estruturado automaticamente |
| **ManutenÃ§Ã£o** | CÃ³digo complexo (900+ linhas) | CÃ³digo simples (300 linhas) |
| **Flexibilidade** | Precisa ajustar regex para cada formato | Adapta-se automaticamente |
| **Subtabelas** | DifÃ­cil de processar | Processa automaticamente |

## ğŸ—ï¸ Nova Estrutura

```
projeto/
â”œâ”€â”€ server_python/          # âœ¨ NOVO: Servidor Python com LlamaIndex
â”‚   â”œâ”€â”€ main.py            # Servidor FastAPI
â”‚   â”œâ”€â”€ requirements.txt   # DependÃªncias Python
â”‚   â”œâ”€â”€ setup.sh          # Script de instalaÃ§Ã£o
â”‚   â””â”€â”€ uploads/          # Uploads temporÃ¡rios
â”œâ”€â”€ server/                # âš ï¸ LEGADO: Servidor Node.js (pode ser removido)
â”‚   â””â”€â”€ index.js
â””â”€â”€ client/                # âœ… Mantido: Front-end React
    â””â”€â”€ ...
```

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida

### 1. Instalar dependÃªncias Python

```bash
cd server_python
./setup.sh
```

Ou manualmente:

```bash
cd server_python
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Configurar variÃ¡veis de ambiente

Edite `server_python/.env`:

```env
PORT=5001
LLM_PROVIDER=openai          # ou "ollama" para usar local
OPENAI_API_KEY=sk-...        # sua chave OpenAI
OCR_ENGINE=paddleocr         # ou "tesseract"
```

### 3. Escolher LLM Provider

#### OpÃ§Ã£o A: OpenAI (recomendado - mais rÃ¡pido)
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-sua-chave
```

#### OpÃ§Ã£o B: Ollama (gratuito, local)
```bash
# Instalar Ollama: https://ollama.ai
ollama pull llama3.2

# No .env:
LLM_PROVIDER=ollama
```

### 4. Escolher OCR Engine

#### OpÃ§Ã£o A: PaddleOCR (recomendado - mais preciso)
```env
OCR_ENGINE=paddleocr
# Instala automaticamente via pip
```

#### OpÃ§Ã£o B: Tesseract (alternativa)
```bash
# macOS
brew install tesseract tesseract-lang

# Ubuntu
sudo apt-get install tesseract-ocr tesseract-ocr-por

# No .env:
OCR_ENGINE=tesseract
```

## ğŸƒ Executar

### Desenvolvimento completo (front + back)

```bash
npm run dev
```

### Apenas servidor Python

```bash
npm run server
# ou
cd server_python
source venv/bin/activate
python main.py
```

### Apenas front-end

```bash
npm run client
```

## ğŸ”„ Como Funciona

```
[Imagem do Boletim]
        â†“
[OCR (PaddleOCR/Tesseract)]
        â†“
[Texto extraÃ­do (com ruÃ­do)]
        â†“
[LlamaIndex + LLM]
        â†“
[JSON estruturado limpo]
        â†“
[CÃ¡lculo de mÃ©dias]
        â†“
[Front-end React]
```

### Exemplo de ExtraÃ§Ã£o

**Entrada (OCR bruto):**
```
FILOSOFIA 0 3.0 6.0 9.0 6.0 0 6.0
GEOGRAFIA 0 10.0 10.0 - 10.0 1.0 10.0
```

**SaÃ­da (JSON estruturado):**
```json
{
  "disciplinas": [
    {
      "nome": "FILOSOFIA",
      "faltas": 0,
      "notas": [3.0, 6.0, 9.0],
      "media_provisoria": 6.0,
      "pontos_extras": 0,
      "media_parcial": 6.0
    },
    {
      "nome": "GEOGRAFIA",
      "faltas": 0,
      "notas": [10.0, 10.0, null],
      "media_provisoria": 10.0,
      "pontos_extras": 1.0,
      "media_parcial": 10.0
    }
  ]
}
```

## ğŸ¯ Vantagens do LlamaIndex

1. **Entende contexto**: Sabe que "FILOSOFIA" Ã© uma disciplina, nÃ£o um nome de aluno
2. **Estrutura automÃ¡tica**: NÃ£o precisa de regex complexo
3. **Lida com variaÃ§Ãµes**: Funciona mesmo se o formato mudar um pouco
4. **ValidaÃ§Ã£o inteligente**: Detecta erros de OCR e corrige
5. **Subtabelas**: Processa automaticamente (ex: Biologia I / Biologia II)

## ğŸ”§ Troubleshooting

### Erro: "No module named 'paddleocr'"
```bash
cd server_python
source venv/bin/activate
pip install paddleocr
```

### Erro: "tesseract is not installed"
```bash
# macOS
brew install tesseract tesseract-lang

# Ubuntu
sudo apt-get install tesseract-ocr tesseract-ocr-por
```

### Erro: "OPENAI_API_KEY not found"
- Configure no `.env` ou use Ollama (`LLM_PROVIDER=ollama`)

### Ollama muito lento
- Use OpenAI para melhor performance
- Ou use modelo menor: `ollama pull llama3.1:8b`

### Porta 5001 em uso
```bash
# Verificar processo
lsof -ti:5001

# Matar processo
kill $(lsof -ti:5001)

# Ou usar outra porta
PORT=5002 python main.py
```

## ğŸ“ MigraÃ§Ã£o do CÃ³digo Antigo

O servidor Node.js antigo (`server/index.js`) ainda existe mas nÃ£o Ã© mais usado. VocÃª pode:

1. **Manter ambos** (para comparaÃ§Ã£o/testes)
2. **Remover o antigo** quando confirmar que o novo funciona:
   ```bash
   rm -rf server/
   ```

## ğŸ“ Recursos

- [LlamaIndex Docs](https://docs.llamaindex.ai/)
- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Ollama](https://ollama.ai/)

